# DeepResearch æœ¬åœ°éƒ¨ç½²è¯´æ˜

## âœ… å·²å®Œæˆçš„é…ç½®

1. **åˆ›å»ºäº† `.env` é…ç½®æ–‡ä»¶**
   - æ¨¡å‹è·¯å¾„ï¼š`Alibaba-NLP/Tongyi-DeepResearch-30B-A3B`
   - æ•°æ®é›†ï¼šä½¿ç”¨ç¤ºä¾‹æ•°æ® `example.jsonl`
   - è¾“å‡ºè·¯å¾„ï¼š`./outputs`
   - GPUé…ç½®ï¼šå·²ä¿®æ”¹ä¸ºä½¿ç”¨4ä¸ªGPU

2. **ä¿®æ”¹äº†å¯åŠ¨è„šæœ¬ `run_react_infer.sh`**
   - ä»8ä¸ªGPUæ”¹ä¸º4ä¸ªGPU
   - ä½¿ç”¨ç«¯å£ 6001-6004

## ğŸš€ æ¥ä¸‹æ¥çš„æ­¥éª¤

### æ–¹æ³•1ï¼šä½¿ç”¨è‡ªåŠ¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /home/intern/jzwww/DeepResearch/inference
bash run_react_infer.sh
```

### æ–¹æ³•2ï¼šæ‰‹åŠ¨å¯åŠ¨ï¼ˆæ›´çµæ´»ï¼‰

#### æ­¥éª¤1ï¼šå¯åŠ¨ vLLM æœåŠ¡

```bash
# å¯åŠ¨4ä¸ªæœåŠ¡å®ä¾‹
cd /home/intern/jzwww/DeepResearch

CUDA_VISIBLE_DEVICES=0 vllm serve Alibaba-NLP/Tongyi-DeepResearch-30B-A3B --host 0.0.0.0 --port 6001 --disable-log-requests > vllm_port1.log 2>&1 &
CUDA_VISIBLE_DEVICES=1 vllm serve Alibaba-NLP/Tongyi-DeepResearch-30B-A3B --host 0.0.0.0 --port 6002 --disable-log-requests > vllm_port2.log 2>&1 &
CUDA_VISIBLE_DEVICES=2 vllm serve Alibaba-NLP/Tongyi-DeepResearch-30B-A3B --host 0.0.0.0 --port 6003 --disable-log-requests > vllm_port3.log 2>&1 &
CUDA_VISIBLE_DEVICES=3 vllm serve Alibaba-NLP/Tongyi-DeepResearch-30B-A3B --host 0.0.0.0 --port 6004 --disable-log-requests > vllm_port4.log 2>&1 &

echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 60

# éªŒè¯æœåŠ¡
curl http://localhost:6001/v1/models
```

#### æ­¥éª¤2ï¼šè¿è¡Œæ¨ç†

```bash
cd /home/intern/jzwww/DeepResearch/inference

python run_multi_react.py \
  --dataset ../inference/eval_data/example.jsonl \
  --output ./outputs \
  --model Alibaba-NLP/Tongyi-DeepResearch-30B-A3B \
  --max_workers 4 \
  --temperature 0.6 \
  --presence_penalty 1.1 \
  --roll_out_count 1
```

## ğŸ“ é…ç½®æ–‡ä»¶è¯´æ˜

### `.env` æ–‡ä»¶ä½ç½®
`/home/intern/jzwww/DeepResearch/.env`

### å½“å‰é…ç½®
- **MODEL_PATH**: `Alibaba-NLP/Tongyi-DeepResearch-30B-A3B`ï¼ˆHugging Face æ¨¡å‹IDï¼‰
- **DATASET**: `./inference/eval_data/example.jsonl`
- **OUTPUT_PATH**: `./outputs`
- **MAX_WORKERS**: 4ï¼ˆå¹¶è¡Œå¤„ç†æ•°ï¼‰
- **ROLLOUT_COUNT**: 1ï¼ˆæ¨ç†è½®æ•°ï¼‰

### å¦‚ä½•ä¿®æ”¹é…ç½®

å¦‚æœä½ æœ‰æ›´å¤šGPUï¼Œå¯ä»¥å¢åŠ å¯åŠ¨çš„æœåŠ¡æ•°ï¼š

1. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š
```bash
nano /home/intern/jzwww/DeepResearch/.env
```

2. ä¿®æ”¹ MAX_WORKERS å’Œå¢åŠ GPUï¼š

ç¼–è¾‘ `run_react_infer.sh`ï¼Œæ·»åŠ æ›´å¤šæœåŠ¡ï¼š
```bash
CUDA_VISIBLE_DEVICES=4 vllm serve $MODEL_PATH --host 0.0.0.0 --port 6005 --disable-log-requests &
# ... ç»§ç»­æ·»åŠ æ›´å¤š
```

å¹¶åœ¨ `main_ports=(6001 6002 6003 6004)` ä¸­æ·»åŠ æ›´å¤šç«¯å£ã€‚

## ğŸ” æ£€æŸ¥çŠ¶æ€

### æŸ¥çœ‹ vLLM æœåŠ¡çŠ¶æ€
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
netstat -tulpn | grep 600

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
tail -f /home/intern/jzwww/DeepResearch/inference/vllm_port1.log
```

### æ£€æŸ¥è¾“å‡ºç»“æœ
```bash
# æŸ¥çœ‹æ¨ç†ç»“æœ
ls -lh /home/intern/jzwww/DeepResearch/outputs/

# æŸ¥çœ‹å…·ä½“ç»“æœå†…å®¹
cat /home/intern/jzwww/DeepResearch/outputs/Tongyi-DeepResearch-30B-A3B_sglang/example/iter1.jsonl
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹åŠ è½½**ï¼šç¬¬ä¸€æ¬¡å¯åŠ¨ vLLM æ—¶ï¼Œæ¨¡å‹ä¼šä» Hugging Face ç¼“å­˜åŠ è½½ï¼Œéœ€è¦ä¸€äº›æ—¶é—´
2. **æ˜¾å­˜è¦æ±‚**ï¼š30B-A3B æ¨¡å‹æ¯ä¸ªå®ä¾‹å¤§çº¦éœ€è¦ 60-80GB æ˜¾å­˜
3. **ä¾èµ–å®‰è£…**ï¼šç¡®ä¿å·²å®‰è£… vLLMï¼š
   ```bash
   pip install vllm
   ```

## ğŸ¯ ä¸‹ä¸€æ­¥

1. æ£€æŸ¥æ˜¯å¦éœ€è¦å·¥å…·APIï¼ˆæœç´¢ã€ç½‘é¡µè®¿é—®ç­‰ï¼‰
2. å‡†å¤‡è‡ªå·±çš„æµ‹è¯•æ•°æ®é›†
3. æŸ¥çœ‹ç”Ÿæˆçš„ç»“æœ

## ğŸ“š ç›¸å…³æ–‡æ¡£

- é¡¹ç›® README: `/home/intern/jzwww/DeepResearch/README.md`
- GitHub: https://github.com/Alibaba-NLP/DeepResearch

